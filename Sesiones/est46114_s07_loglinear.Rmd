---
title: "S07 - Modelos Log-lineales"
author: "Juan Carlos Martinez-Ovando"
date: "Primavera 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

**Objetivo**

En esta sesion aprenderemos los fundamentos matematicos de los modelos log-lineales para analizar datos categoriucos multivariados agrupados como tablas de contingencia.

* Revisamos la implementacion practica de estos modelos empleando el paradigma frecuentista.

* En la siguiente sesion revisaremos su contraparte bayesiana.

Estudiamos estos modelos como preludio de los modelos multidireccionales (a.k.a. *multi-way models*) y de los modelos de grafos probabilisticos.

---

# Parte 1 - Fundamentos

## Un poco de teoria

* Suponemos que tenemos $N$ variables categoricas multidimensionales, indizados por $n=1,2,\ldots,N$. 

* Cada una de las $N$ variables corresponde a mediciones $d$-dimensionales de datos discretos categoricos.

* Denotamos la coleccion de las variables discretas categoricas como $$X=(X_{v}),$$ y referimos a los valores categoricos como niveles.

* Asi, una observacion generica se referira a $$i_j=(i_{j,1},i_{j,2},\ldots,i_{j,d}),$$
donde cada $i_{j,k} \in \{1,2,\ldots,I_k\},$ siendo $I_k$ el numero de categorias de las $k$-esima dimension.

* El conjunto donde todas las $i_j$ toman valores (i.e. producto cartesiano de los $k$ conjuntos $\{1,2,\ldots,I_k\}$) se denota por $\mathcal{I}$.

### Supuestos

En el enfoque frecuentista, es comun suponer que las observaciones son mutuaente independientes estocasticamente. Asi, la distriucion conjunta de las $N$ observaciones queda expresada como $$p(X_1=i_1,\ldots,X_N=i_N)=\prod_{j=1}^{N}p(X_j=i_j)=\prod_{i\in \mathcal{I}}P(i)^{n(i)},$$
donde $$P(i)=p(X=i),$$ para todo $i\in \mathcal{I}$ y $$n(i)=\#\{X_n:X_n=i,n=1,\ldots,N\}.$$

### Tabla de contingencia

Resumiendo la informacion de las $N$ observaciones en una tabla de contingencia, por el supuesto de independencia estocastica entre observaciones, se obtiene que la distribucion conjunta de la misma tabla es
$$P\left(\{n(i)\}_{i\in\mathcal{I}}\right)\propto \prod_{i\in \mathcal{I}}P(i)^{n(i)},$$
siendo la contante de propocionalidad igual al componente combinatorio $\frac{N!}{\prod_{i\in\mathcal{I}}n(i)!}.$

Las dos expresiones anteriores, $P\left(\{n(i)\}_{i\in\mathcal{I}}\right)$ y $p(X_1=i_1,\ldots,X_N=i_N)$, representan la **verosimilitud** de los datos/informacion para el conjunto de **parametros** $$\theta=\{p(i)\}_{i\in\mathcal{I}}.$$

### Modelo saturado

Asi, el modelo descrito antes, haciendo el supuesto generico sobre $\theta$ donde $$p(i)\geq 0$$ para todo $i\in\mathcal{I}$ y $$\sum_{i\in\mathcal{I}}p(i)=1,$$ se conoce como **modelo saturado.**

* El modelo saturado es generico, pero en ocasiones poco informativo. En alguna ocasiones se requiere *imponer restricciones* adicionales sobre los $p(i)$s. Eso lo veremos en la siguiente sesion.

### Inferencia

Considerando el **modelo saturado** se obtiene directamente que el estimador maximo versosimil para $\theta$ esta dado por $$\widehat{\theta}=\{\widehat{p(i)}\}_{i\in\mathcal{I}},$$ donde $$\widehat{p(i)}=\frac{n(i)}{N}.$$

* Observen que en este caso, no se incorpora la incertidumbre epistemica sobre $\hat{\theta}.$

Retomando la informacion respecto a la **tabla de contingencia** $\{m_{i}\}_{i\in\mathcal{I}}$ se tiene que $$\mathbb{E}(m_{i})=N\widehat{p(i)},$$ para $i\in\mathcal{I}.$

## Modelo jerarquico log-lineal

Los **modelos jerarquicos log-lineales** expresan los componentes de $\theta$ como productos de _factores marginales_ y _factores combinados_ (o _factores de interaccion_) de las diferentes dimensiones que componen la **tabla de contigencia** $\{m_i\}_{i\in\mathcal{I}}.$

Ilustrando esta idea con una tabla de contingencia de tres dimensiones $\{m_i\}_{i\in\mathcal{I}}$ en la que $$i=(j,k,l),$$ para $j=1,\ldots,J$, $k=1,\ldots,K$ y $l=1,\ldots,L$. Asi, $$\mathcal{I}=\{(j,k,l)\}_{j,k,l}.$$

### Modelo saturado

En el caso del **modelo saturado** para la tabla de contingencia de tres dimnesiones, tenemos que los parametros $\theta=\{p(i)\}_{i\in\mathcal{I}}$ son reparametrizados como $$p(i)=u \cdot u_{j} \cdot u_{k} \cdot u_{l} \cdot u_{jk} \cdot u_{jl} \cdot u_{kl} \cdot u_{jkl}.$$

* Podria dar la apariencia que la reparametrizacion anterior es "demasiado" saturada. Sin embargo, no es el caso, pues admite la posibilidad de que algunos de los componentes $p(i)$ puedan ser iguales a 0. 

Los componentes $u_{s}$s representan los factores del modelo. Asi, el componente $u$ representa el _factor comun_, los $u_{w}$s representan los _factores principales_, los componentes $u_{wv}$s representan los _factores de interaccion de segundo orden_ y el componente $u_{jkl}$ represental el _factor de interaccion de tercer orden_.

### Modelo de efectos principales

El **modelo de efector principales** es expresado como $$p(i)=u \cdot u_{j} \cdot u_{k} \cdot u_{l},$$ para $i\in\mathcal{I}.$ Comunmente, este modelo es expresado en su version aditiva,
$$log(p(i))=\tilde{u}+\tilde{u}_{j}+\tilde{u}_{k}+\tilde{u}_{l}.$$

## Ajuste del modelo

Retomemos el modelo general para la **tabla de contingencia** $\{m_{i}\}_{i\in\mathcal{I}}$. La version logaritmica de la verosimilitud maximizada para un conjunto de datos $\{n(i)\}_{iin\mathcal{I}}$ esta expresada como $$l=\sum_{i\in\mathcal{I}}n(i) log\left(\widehat{p(i)}\right).$$

La evaluacion de que tan adecuado es el modelo para un conjunto de datos $\{n(i)\}_{i\in\mathcal{I}}$ puede realizarse en terminos de la **devianza** del modelo.

### Devianza

La devianza del modelo para tablas de contingencia se define como dos veces la verosimilitud del **modelo** contrastado con el **modelo saturado**. Denotemos por $l_s$ a la log-verosimilitud del modelo saturado y por $l$ la verosimilitud del modelo que consideremos en cuestion, la devianza se define entonces como \begin{eqnarray}D & = & 2\left(\hat{l}_s-\hat{l}\right)\\ & = & 2\sum_{i\in\mathcal{I}} n(i)log\left(\frac{n(i)}{\widehat{m(i)}}\right).\end{eqnarray}

* El calculo anterior requiere la posibilidad de ajustar/estimar el **modelo saturado**. En el caso de los modelos log-lineales este es el caso. **Revisen por favor por que pasa esto.**

* La distribucion asintotica de $D$ es $\Xi^{2}(k)$ donde $k=p_s-p$ siendo $p_s$ el _numero de parametros del modelo saturado_ y $p$ el _numero de parametros del modelo en cuestion_.

* La devianza $D$ nos brinda una medida para evaluar el ajuste del modelo (considerando el **modelo saturado** como la alternativa de referencia).

---

# Parte 2 - Practica

Ilustraremos el materia anterior en R version 3.4.4.

```{r eval=FALSE, include=FALSE}
#if(!require('graph')){install.packages("graph")}
#library("graph")

#if(!require('RBGL')){install.packages("RBGL")}
#library("RBGL")

if(!require('gRbase')){install.packages("gRbase")}
library("gRbase")

if(!require('gRim')){install.packages("gRim")}
library("gRim")
```

---


# Siguientes temas:

* Implementacion bayesiana de los modelos log-lineales (incorporando la incertidumbre epistemica).

* Revision de la devianza bayesiana y contraste de modelos.

* Vinculacion del modelo jerarquico log-lineal con los modelos de grafos probabilisticos.